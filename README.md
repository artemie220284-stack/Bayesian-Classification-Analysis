# Naive Bayes Classifier with Detailed Probability Analysis

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![Machine Learning](https://img.shields.io/badge/Machine%20Learning-Bayesian-orange)
![License](https://img.shields.io/badge/License-MIT-green)
![Probability](https://img.shields.io/badge/Probabilistic%20Modeling-Interpretable-purple)

A comprehensive implementation of Naive Bayes classifier with transparent probability calculations, feature contribution analysis, and interpretable predictions for agricultural product quality assessment.

## ğŸ‰ Overview

This project implements a Naive Bayes classifier specifically designed for watermelon quality prediction, featuring detailed probability decomposition and transparent decision-making. The system provides not only predictions but also complete mathematical breakdowns showing how each feature contributes to the final classification.

### ğŸ¯ Key Features
- **Complete Probability Calculations**: Prior, likelihood, and posterior probabilities
- **Feature Contribution Analysis**: Visual breakdown of each feature's impact
- **Mixed Data Types**: Handles both discrete (categorical) and continuous (numeric) features
- **Laplace Smoothing**: Robust probability estimation for unseen categories
- **Interpretable Outputs**: Transparent decision-making with mathematical details
- **Watermelon Dataset**: Realistic agricultural quality prediction scenario

### ğŸ“Š Sample Prediction Analysis
For a sample watermelon with features: *é’ç»¿ï¼Œèœ·ç¼©ï¼ŒæµŠå“ï¼Œæ¸…æ™°ï¼Œå‡¹é™·ï¼Œç¡¬æ»‘ï¼Œå¯†åº¦=0.697ï¼Œå«ç³–ç‡=0.460*

**Prediction**: å¥½ç“œ (Good Melon) with 99.8% confidence

**Probability Breakdown**:
- **Bad Melon Total Log-Probability**: -9.920
- **Good Melon Total Log-Probability**: -3.826
- **Key Contributing Features**: å¯†åº¦ (density) +0.674, å«ç³–ç‡ (sugar content) -0.402

## ğŸ—ï¸ System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input Features â”‚
â”‚ â€¢ Discrete: è‰²æ³½, æ ¹è’‚, æ•²å£°, çº¹ç†, è„éƒ¨, è§¦æ„Ÿ â”‚
â”‚ â€¢ Continuous: å¯†åº¦, å«ç³–ç‡ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Naive Bayes Classifier â”‚
â”‚ â€¢ Prior Probability Estimation â”‚
â”‚ â€¢ Conditional Probability Calculation â”‚
â”‚ â€¢ Laplace Smoothing â”‚
â”‚ â€¢ Gaussian Distribution for Continuous â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Probability Decomposition â”‚
â”‚ â€¢ Log-probability Calculations â”‚
â”‚ â€¢ Feature Contribution Analysis â”‚
â”‚ â€¢ Confidence Scoring â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Interpretable Output â”‚
â”‚ â€¢ Final Prediction â”‚
â”‚ â€¢ Probability Distribution â”‚
â”‚ â€¢ Feature Impact Visualization â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
